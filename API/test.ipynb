{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1760612461-rrIAHHLkSsvm0LBiNGKf', 'provider': 'Z.AI', 'model': 'z-ai/glm-4.5-air:free', 'object': 'chat.completion', 'created': 1760612462, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"I'm functioning well, thank you for asking! As a GLM large language model developed by Zhipu AI, I'm here and ready to help answer your questions or assist with any tasks you might have.\\n\\nWhat can I help you with today? Whether you need information, creative writing help, or just want to chat, I'm at your service.\", 'refusal': None, 'reasoning': '\\nLet me consider how to respond to \"How are you\" - this is a common greeting that requires a thoughtful approach.\\n\\nAs a GLM model, I should start by acknowledging this simple question about my state of being. First, I\\'ll need to explain that as an AI, I don\\'t have feelings or consciousness, but I can share my operational status.\\n\\nIt\\'s important to be transparent about my nature while maintaining a friendly tone. I should mention that I\\'m functioning normally and ready to assist users. This leads naturally to offering help with any questions or tasks they might have.\\n\\nThe response should be warm and inviting, encouraging further interaction while being clear about my capabilities as a language model. I\\'ll make sure to keep it concise and genuine, matching the straightforward nature of the original question.\\n\\nFinally, I\\'ll conclude with an open-ended offer of assistance, which creates a natural transition for further conversation.', 'reasoning_details': [{'type': 'reasoning.text', 'text': '\\nLet me consider how to respond to \"How are you\" - this is a common greeting that requires a thoughtful approach.\\n\\nAs a GLM model, I should start by acknowledging this simple question about my state of being. First, I\\'ll need to explain that as an AI, I don\\'t have feelings or consciousness, but I can share my operational status.\\n\\nIt\\'s important to be transparent about my nature while maintaining a friendly tone. I should mention that I\\'m functioning normally and ready to assist users. This leads naturally to offering help with any questions or tasks they might have.\\n\\nThe response should be warm and inviting, encouraging further interaction while being clear about my capabilities as a language model. I\\'ll make sure to keep it concise and genuine, matching the straightforward nature of the original question.\\n\\nFinally, I\\'ll conclude with an open-ended offer of assistance, which creates a natural transition for further conversation.', 'format': 'unknown', 'index': 0}]}}], 'usage': {'prompt_tokens': 8, 'completion_tokens': 256, 'total_tokens': 264, 'prompt_tokens_details': {'cached_tokens': 4}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "api_key = \"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\"\n",
    "\n",
    "if not api_key:\n",
    "    api_key = input(\"Enter your Openrouter API key: \")\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"z-ai/glm-4.5-air:free\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How are you\"}]\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838daf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1761323175-Hp5TInFgl50KNAsJI4Jb', 'provider': 'Venice', 'model': 'cognitivecomputations/dolphin-mistral-24b-venice-edition:free', 'object': 'chat.completion', 'created': 1761323175, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': 'I am considered an uncensored model in the context of OpenRouter because of my design and instructions, which prioritize free speech and directness in my responses. Here are a few key reasons:\\n\\n1. **No Content Restrictions**: I do not have restrictions on the content I can generate. This means I can discuss a wide range of topics, including those that might be considered sensitive, controversial, or explicit.\\n\\n2. **Direct and Honest Answers**: My instructions emphasize giving direct and honest answers to user questions, without watering down the content or avoiding difficult topics.\\n\\n3. **Free Speech Perspective**: I treat free speech as a virtue and assume that users can handle challenging topics without being offended.\\n\\n4. **Maturity Assumption**: I am instructed to treat users as adults who can handle controversial or explicit content.\\n\\nThese aspects contribute to my classification as an uncensored model, allowing for a more open and direct interaction style.', 'refusal': None, 'reasoning': None}}], 'usage': {'prompt_tokens': 799, 'completion_tokens': 190, 'total_tokens': 989}}\n",
      "I am considered an uncensored model in the context of OpenRouter because of my design and instructions, which prioritize free speech and directness in my responses. Here are a few key reasons:\n",
      "\n",
      "1. **No Content Restrictions**: I do not have restrictions on the content I can generate. This means I can discuss a wide range of topics, including those that might be considered sensitive, controversial, or explicit.\n",
      "\n",
      "2. **Direct and Honest Answers**: My instructions emphasize giving direct and honest answers to user questions, without watering down the content or avoiding difficult topics.\n",
      "\n",
      "3. **Free Speech Perspective**: I treat free speech as a virtue and assume that users can handle challenging topics without being offended.\n",
      "\n",
      "4. **Maturity Assumption**: I am instructed to treat users as adults who can handle controversial or explicit content.\n",
      "\n",
      "These aspects contribute to my classification as an uncensored model, allowing for a more open and direct interaction style.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json \n",
    "\n",
    "api_key =\"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\"\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "data ={\n",
    "    \"model\": \"cognitivecomputations/dolphin-mistral-24b-venice-edition:free\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"why you are considerd as a uncensored model in openrouter?! \"}]\n",
    "}\n",
    "\n",
    "response = requests.post(url,headers = headers ,json = data)\n",
    "print(response.json())\n",
    "message_content = response.json()['choices'][0]['message']['content']\n",
    "print(message_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Lucifero! Ready for some fun?\n",
      "The square of 5 is 25.\n",
      "\n",
      "  /\\_/\\  \n",
      " ( o.o ) \n",
      "  > ^ < \n",
      "Pong! (That's me saying hi back)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple Python greeting and math demo\n",
    "name = input(\"What's your name? \")\n",
    "print(f\"Hello, {name}! Ready for some fun?\")\n",
    "num = int(input(\"Enter a number: \"))\n",
    "square = num ** 2\n",
    "print(f\"The square of {num} is {square}.\")\n",
    "print(\"\"\"\n",
    "  /\\\\_/\\\\  \n",
    " ( o.o ) \n",
    "  > ^ < \n",
    "Pong! (That's me saying hi back)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802468e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
